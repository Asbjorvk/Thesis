# Importing packages
import deepxde as dde
import numpy as np
import matplotlib.pyplot as plt

# Variables 
h = 1 # m
tmin, tmax = 0, 1 # s or year
# Refernace value that the network is looking for is
# cv = 0.2 # m^2/(s or year)
cv = dde.Variable(-0.2)

# Defining the PDE for the consolidation equation t > 0
def PDE(x,y):
    dp_t = dde.grad.jacobian(y,x, j = 1)
    dp_xx = dde.grad.hessian(y,x, j = 0)
    return (dp_t - cv * dp_xx)


# Importing and structurizing trainingdata
def Get_TrainData(N):
    # This function imports the dataset from the analytical solution and extrapolates N number of random  points within the dataset. 
    # Which is then used as the traningdata for the model. 
    
    if N > 10000:
        print('Exceedes number of points availible. Try lower number')
        exit()
    
    # Importing data
    data = np.load('Data_anasol_DrainedTop_DrainedBottom.npz')
    z, t, p = data['z'].flatten()[:, None], data['t'].flatten()[:,None], data['p'].T
    
    # Create meshgrid
    Z, T = np.meshgrid(z, t)
    zt_grid = np.hstack( (Z.flatten()[:,None], T.flatten()[:, None]) )
    p_grid = p.flatten()[:, None]
    
    # Sample data
    idx = np.random.choice(zt_grid.shape[0], N, replace = False)
    zt_sample = zt_grid[idx, :]
    p_sample = p_grid[idx, :]
    
    # creating traningsets
    z_train = zt_sample[:, 0:1]
    t_train = zt_sample[:, 1:2]
    p_train = p_sample
    
    return np.hstack( (z_train, t_train) ), p_train

# Defining the function for the initial conditions
def IC(x):
    # Normalized value for the initial conditions representing p/p0 from the analytical solution'
    # This returns the value of 1 for the initial conditions at t = 0
    return 1

# Defining boundary conditions 
def BC(x):
    # The boundary conditions that are supposed to be specified here is p = 0  at t > 0
    # As shown later in the script, represents the dirichelt boundary conditions
    return 0


# Defining geometry for space and time
geom = dde.geometry.Interval(-h/2, h/2)
timedomain = dde.geometry.TimeDomain(tmin, tmax)
geomtime = dde.geometry.GeometryXTime(geom, timedomain)

# Defining boundary and initial conditions
bc = dde.icbc.DirichletBC(geomtime, BC, lambda _, on_boundary: on_boundary)
ic = dde.icbc.IC(geomtime, IC, lambda _, on_initial: on_initial)

# Importing data and creating the two things to observe
observe_x, P = Get_TrainData(2000) # Samples N random point from the dataset, but not more than 10 000 points can be sampled
observe_y = dde.icbc.PointSetBC(observe_x, P)

# Specifying the characteristics for the model
data = dde.data.TimePDE(
    geomtime, 
    PDE, 
    [bc, ic, observe_y],
    num_domain = 400, 
    num_boundary = 200, 
    num_initial = 100, 
    anchors = observe_x, 
    train_distribution = 'LHS' 
    )

# Variables of the neural network
activation = 'tanh'
initializer = 'Glorot uniform'
hidden_layers = ( [2] + [32] * 3 + [1] )
net = dde.nn.FNN(hidden_layers, activation, initializer)

# Compiling and initiating the model
model = dde.Model(data, net)
model.compile('adam', lr = 0.001, external_trainable_variables= [cv], 
               )
# Storing variables
filename = 'Variables - Inverse analysis for Drained top and bottom.dat'
variable = dde.callbacks.VariableValue(cv, period = 1000, filename = filename)

# Training and saving the model
losshistory, train_state = model.train(iterations = 20000, callbacks = [variable])
dde.saveplot(losshistory, train_state, issave = True, isplot = True)

# Plotting the data
# filename = 'Variables - Inverse analysis for Drained top and bottom.txt'
predicted_data1 = np.loadtxt(filename, delimiter = ' ', dtype = str)

# Structurizing data
epochs1 = []
pred_cv1 = []
for i in predicted_data1:
    epochs1.append(float(i[0]))
    pred_cv1.append(float(i[1][1:-1]))


# Plotting of the data
fig, ax1 = plt.subplots()
ax1.hlines(y = 0.2, xmin = 0, xmax = max(epochs1), color = 'orangered', linestyles = '-', label = 'Actual value of Cv = 0.2')
ax1.plot(epochs1, pred_cv1, linestyle = '--', label = 'Approximation done by PINN')
# ax1.set_xlabel('Epochs')
ax1.set_ylabel('Cv [m^2/yr]')
ax1.set_xlabel('Epochs')
ax1.set_title('Inverse analysis for drained top and bottom')
ax1.grid()
ax1.legend()
plt.tight_layout()
pre = pred_cv1[-1]
print('{0:.6f}'.format(pre))
